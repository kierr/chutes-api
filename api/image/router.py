"""
Routes for images.
"""

import io
import uuid
import asyncio
import orjson as json
from loguru import logger
from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    status,
    File,
    Form,
    UploadFile,
    Response,
    Request,
)
from fastapi_cache.decorator import cache
from starlette.responses import StreamingResponse
from sqlalchemy import and_, or_, exists, func
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from typing import Optional
from api.image.schemas import Image
from api.chute.schemas import Chute
from api.user.schemas import User
from api.user.service import get_current_user
from api.database import get_db_session
from api.config import settings
from api.image.response import ImageResponse
from api.image.util import get_image_by_id_or_name
from api.pagination import PaginatedResponse
from api.util import limit_images, semcomp
from api.permissions import Permissioning

router = APIRouter()


@router.get("/{image_id}/logs")
async def stream_build_logs(
    image_id: str,
    offset: Optional[str] = None,
    db: AsyncSession = Depends(get_db_session),
    current_user: User = Depends(get_current_user(purpose="images", raise_not_found=False)),
):
    image = (
        (await db.execute(select(Image).where(Image.image_id == image_id)))
        .unique()
        .scalar_one_or_none()
    )
    if not image or (
        not image.public and (not current_user or image.user_id != current_user.user_id)
    ):
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Image not found, or does not belong to you",
        )

    # Images already built?
    if image.status.startswith(("built and pushed", "error:")):
        async with settings.s3_client() as s3:
            log_path = f"forge/{image.user_id}/{image.image_id}.log"
            try:
                async with settings.s3_client() as s3:
                    data = io.BytesIO()
                    await s3.download_fileobj(settings.storage_bucket, log_path, data)
                    headers = {
                        "Content-Disposition": f'inline; filename="{image_id}.log"',
                        "Content-Type": "text/plain; charset=utf-8",
                    }
                    return Response(
                        content=data.getvalue(),
                        headers=headers,
                    )
            except Exception:
                return Response(
                    content=image.status,
                    headers={"Content-Type": "text/plain"},
                )

    # Stream the logs in real-time.
    async def _stream():
        nonlocal offset, image_id
        last_offset = offset
        while True:
            stream_result = None
            try:
                stream_result = await settings.redis_client.xrange(
                    f"forge:{image_id}:stream", last_offset or "-", "+"
                )
            except Exception as exc:
                logger.error(f"Error fetching stream result: {exc}")
                yield f"data: ERROR: {exc}"
                return
            if not stream_result:
                yield ".\n"
                await asyncio.sleep(1.0)
                continue
            for offset, data in stream_result:
                last_offset = offset.decode()
                parts = last_offset.split("-")
                last_offset = parts[0] + "-" + str(int(parts[1]) + 1)
                if data[b"data"] == b"DONE":
                    await settings.redis_client.delete(f"forge:{image_id}:stream")
                    yield "DONE\n"
                    break
                log_obj = json.loads(data[b"data"])
                sse_data = json.dumps({"log": log_obj, "offset": last_offset}).decode()
                yield f"data: {sse_data}\n"

    return StreamingResponse(
        _stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
        },
    )


@cache(expire=60)
@router.get("/", response_model=PaginatedResponse)
async def list_images(
    include_public: Optional[bool] = False,
    name: Optional[str] = None,
    tag: Optional[str] = None,
    page: Optional[int] = 0,
    limit: Optional[int] = 25,
    db: AsyncSession = Depends(get_db_session),
    current_user: User = Depends(get_current_user(purpose="images")),
):
    """
    List (and optionally filter/paginate) images.
    """
    logger.debug(f"Listing images for user {current_user.username}")
    query = select(Image)

    # Filter by public and/or only the user's images.
    if include_public:
        query = query.where(
            or_(
                Image.public.is_(True),
                Image.user_id == current_user.user_id,
            )
        )
    else:
        query = query.where(Image.user_id == current_user.user_id)

    # Filter by name/tag/etc.
    if name and name.strip():
        query = query.where(Image.name.ilike(f"%{name}%"))
    if tag and tag.strip():
        query = query.where(Image.tag.ilike(f"%{tag}%"))

    # Perform a count.
    total_query = select(func.count()).select_from(query.subquery())
    total_result = await db.execute(total_query)
    total = total_result.scalar() or 0

    # Pagination.
    query = (
        query.order_by(Image.created_at.desc())
        .offset((page or 0) * (limit or 25))
        .limit((limit or 25))
    )

    result = await db.execute(query)
    return {
        "total": total,
        "page": page,
        "limit": limit,
        "items": [ImageResponse.from_orm(item) for item in result.scalars().all()],
    }


@router.get("/{image_id_or_name:path}", response_model=ImageResponse)
async def get_image(
    image_id_or_name: str,
    db: AsyncSession = Depends(get_db_session),
    current_user: User = Depends(get_current_user(purpose="images")),
):
    """
    Load a single image by ID or name.
    """
    image = await get_image_by_id_or_name(image_id_or_name, db, current_user)
    if not image:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Image not found, or does not belong to you",
        )
    return image


@router.delete("/{image_id_or_name:path}")
async def delete_image(
    image_id_or_name: str,
    db: AsyncSession = Depends(get_db_session),
    current_user: User = Depends(get_current_user(purpose="images")),
):
    """
    Delete an image by ID or name:tag.
    """
    image = await get_image_by_id_or_name(image_id_or_name, db, current_user)
    if not image or image.user_id != current_user.user_id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Image not found, or does not belong to you",
        )

    # No deleting images that have an associated chute.
    if (await db.execute(select(exists().where(Chute.image_id == image.image_id)))).scalar():
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="Image is in use by one or more chutes",
        )
    image_id = image.image_id
    await db.delete(image)
    await db.commit()

    await settings.redis_client.publish(
        "miner_broadcast",
        json.dumps(
            {
                "reason": "image_deleted",
                "data": {
                    "image_id": image_id,
                },
            }
        ).decode(),
    )

    return {"image_id": image_id, "deleted": True}


@router.post("/", status_code=status.HTTP_202_ACCEPTED)
async def create_image(
    request: Request,
    wait: bool = Form(...),
    build_context: UploadFile = File(...),
    username: str = Form(...),
    name: str = Form(...),
    readme: str = Form(...),
    logo_id: str = Form(...),
    tag: str = Form(...),
    dockerfile: str = Form(...),
    image: str = Form(...),
    public: bool = Form(...),
    db: AsyncSession = Depends(get_db_session),
    current_user: User = Depends(get_current_user()),
):
    """
    Create an image; really here we're just storing the metadata
    in the DB and kicking off the image build asynchronously.
    """
    if current_user.username != username:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Cannot make images for users other than yourself!",
        )
    await limit_images(db, current_user)

    # Check for legacy versions.
    chutes_sdk_version = request.headers.get("X-Chutes-Version", "0.0.0").lower() or "0.0.0"
    logger.warning(
        f"Attempt to build image with: {chutes_sdk_version=} from {current_user.username=} {current_user.user_id=}"
    )
    if semcomp(chutes_sdk_version, "0.3.61") < 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Please upgrade your local chutes lib to version >= 0.3.61, e.g. `pip3 install chutes==0.3.61` and try again",
        )

    # Make sure user has reasonable balance before allowing image creation.
    if not current_user.has_role(Permissioning.unlimited_dev):
        effective_balance = (
            current_user.current_balance.effective_balance if current_user.current_balance else 0.0
        )
        if effective_balance < 50.0:
            raise HTTPException(
                status_code=status.HTTP_402_PAYMENT_REQUIRED,
                detail="You must have a balance of >= $50 to create images.",
            )

    image_id = str(uuid.uuid5(uuid.NAMESPACE_OID, f"{username.lower()}/{name}:{tag}"))
    query = select(
        exists().where(
            or_(
                Image.image_id == image_id,
                and_(
                    Image.user_id == current_user.user_id,
                    Image.name == name,
                    Image.tag == tag,
                ),
            )
        )
    )
    if (await db.execute(query)).scalar():
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Image with {name=} and {tag=} aready exists",
        )

    # Upload the build context to our S3-compatible storage backend.
    for obj, destination in (
        (build_context, f"forge/{current_user.user_id}/{image_id}.zip"),
        (
            io.BytesIO(dockerfile.encode()),
            f"forge/{current_user.user_id}/{image_id}.Dockerfile",
        ),
        (
            io.BytesIO(image.encode()),
            f"forge/{current_user.user_id}/{image_id}.pickle",
        ),
    ):
        logger.info(f"Trying to upload: {destination}")
        async with settings.s3_client() as s3:
            await s3.upload_fileobj(obj, settings.storage_bucket, destination)
        logger.success(
            f"Uploaded build context component {image_id=} to {settings.storage_bucket}/{destination}"
        )

    # Create the image once we've persisted the context, which will trigger the build via events.
    image = Image(
        image_id=image_id,
        user_id=current_user.user_id,
        name=name,
        readme=readme,
        logo_id=logo_id if logo_id and logo_id != "__none__" else None,
        tag=tag,
        public=public,
        chutes_version=settings.chutes_version,
    )
    db.add(image)
    await db.commit()
    await db.refresh(image)

    # Clean up any previous streams, just in case of retry.
    await settings.redis_client.delete(f"forge:{image_id}:stream")

    # Stream logs for clients who set the "wait" flag.
    async def _stream_redirect_for_old_chutes():
        yield f'data: {"redirect": "/images/{image_id}/stream", "reason": "log streaming is now a separate endpoint, please update chutes library"}\n'

    if wait:
        return StreamingResponse(_stream_redirect_for_old_chutes())

    return image
