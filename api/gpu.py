"""
GPU constants, expected values, etc.
"""

ALLOW_INCLUDE = ["h100", "h100_sxm", "h100_nvl", "h200", "b200", "mi300x"]
SUPPORTED_GPUS = {
    "3090": {
        "model_name_check": "RTX 3090",
        "memory": 24,
        "major": 8,
        "minor": 6,
        "tensor_cores": 328,
        "concurrent_kernels": True,
        "ecc": False,
        "sxm": False,
        "processors": 82,
        "clock_rate": {"base": 1395, "boost": 1695},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.25,
        "graval": {
            "estimate": 70,
            "iterations": 1,
        },
    },
    "4090": {
        "model_name_check": "RTX 4090",
        "memory": 24,
        "major": 8,
        "minor": 9,
        "tensor_cores": 512,
        "concurrent_kernels": True,
        "ecc": False,
        "sxm": False,
        "processors": 128,
        "clock_rate": {"base": 2235, "boost": 2520},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.4,
        "graval": {
            "iterations": 2,
            "estimate": 65,
        },
    },
    "5090": {
        "model_name_check": "RTX 5090",
        "memory": 32,
        "major": 12,
        "minor": 0,
        "tensor_cores": 680,
        "max_threads_per_processor": 1536,
        "concurrent_kernels": True,
        "ecc": False,
        "sxm": False,
        "processors": 170,
        "clock_rate": {"base": 2017, "boost": 2407},
        "hourly_rate": 0.7,
        "graval": {
            "iterations": 2,
            "estimate": 60,
        },
    },
    "a4000": {
        "model_name_check": "RTX A4000(?! Ada)",
        "memory": 16,
        "major": 8,
        "minor": 6,
        "tensor_cores": 168,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 48,
        "clock_rate": {"base": 765, "boost": 1560},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.2,
        "graval": {
            "iterations": 1,
            "estimate": 75,
        },
    },
    "a4000_ada": {
        "model_name_check": "RTX 4000 Ada",
        "memory": 20,
        "major": 8,
        "minor": 9,
        "tensor_cores": 192,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 48,
        "clock_rate": {"base": 765, "boost": 2175},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.21,
        "graval": {
            "iterations": 1,
            "estimate": 80,
        },
    },
    "a5000": {
        "model_name_check": "RTX A5000",
        "memory": 24,
        "major": 8,
        "minor": 6,
        "tensor_cores": 256,
        "concurrent_kernels": True,
        "ecc": False,
        "sxm": False,
        "processors": 64,
        "clock_rate": {"base": 1170, "boost": 1695},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.25,
        "graval": {
            "iterations": 1,
            "estimate": 92,
        },
    },
    "a6000": {
        "model_name_check": "RTX A6000(?! Ada)",
        "memory": 48,
        "major": 8,
        "minor": 6,
        "tensor_cores": 336,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 84,
        "clock_rate": {"base": 1455, "boost": 1860},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.5,
        "graval": {
            "iterations": 1,
            "estimate": 140,
        },
    },
    "a6000_ada": {
        "model_name_check": "RTX 6000 Ada",
        "memory": 48,
        "major": 8,
        "minor": 9,
        "tensor_cores": 568,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 142,
        "clock_rate": {"base": 915, "boost": 2505},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.75,
        "graval": {
            "iterations": 1,
            "estimate": 60,
        },
    },
    "pro_6000": {
        "model_name_check": "RTX PRO 6000",
        "memory": 96,
        "processors": 188,
        "clock_rate": {"base": 1590, "boost": 2617},
        "max_threads_per_processor": 1024,
        "hourly_rate": 1.8,
        "graval": {
            "iterations": 1,
            "estimate": 103,
        },
    },
    "l4": {
        "model_name_check": "L4(?!0)",
        "memory": 24,
        "major": 8,
        "minor": 9,
        "tensor_cores": 240,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 58,
        "clock_rate": {"base": 795, "boost": 2040},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.25,
        "graval": {
            "iterations": 1,
            "estimate": 85,
        },
    },
    "a10": {
        "model_name_check": "A10(?!0)(?!G)",
        "memory": 24,
        "major": 8,
        "minor": 6,
        "tensor_cores": 208,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 72,
        "clock_rate": {"base": 1110, "boost": 1710},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.25,
        "graval": {
            "iterations": 1,
            "estimate": 82,
        },
    },
    "a40": {
        "model_name_check": "A40",
        "memory": 48,
        "major": 8,
        "minor": 6,
        "tensor_cores": 336,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 84,
        "clock_rate": {"base": 1305, "boost": 1740},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.5,
        "graval": {
            "iterations": 1,
            "estimate": 142,
        },
    },
    "l40": {
        "model_name_check": "L40(?!S)",
        "memory": 48,
        "major": 8,
        "minor": 9,
        "tensor_cores": 568,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 142,
        "clock_rate": {"base": 735, "boost": 2490},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.55,
        "graval": {
            "iterations": 1,
            "estimate": 60,
        },
    },
    "l40s": {
        "model_name_check": "L40S",
        "memory": 48,
        "major": 8,
        "minor": 9,
        "tensor_cores": 568,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 142,
        "clock_rate": {"base": 1065, "boost": 2520},
        "max_threads_per_processor": 1536,
        "hourly_rate": 0.85,
        "graval": {
            "iterations": 1,
            "estimate": 60,
        },
    },
    "a100_40gb": {
        "model_name_check": "A100.?PCIE.?40GB",
        "memory": 40,
        "major": 8,
        "minor": 0,
        "tensor_cores": 432,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 108,
        "clock_rate": {"base": 1065, "boost": 1410},
        "max_threads_per_processor": 2048,
        "hourly_rate": 1.1,
        "graval": {
            "iterations": 4,
            "estimate": 60,
        },
    },
    "a100_40gb_sxm": {
        "model_name_check": "A100.?SXM.?.?40GB",
        "memory": 40,
        "major": 8,
        "minor": 0,
        "tensor_cores": 432,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": True,
        "processors": 108,
        "clock_rate": {"base": 1065, "boost": 1410},
        "max_threads_per_processor": 2048,
        "hourly_rate": 1.15,
        "graval": {
            "iterations": 4,
            "estimate": 60,
        },
    },
    "a100": {
        "model_name_check": "A100.?80GB.?PCIe",
        "memory": 80,
        "major": 8,
        "minor": 0,
        "tensor_cores": 432,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 108,
        "clock_rate": {"base": 1065, "boost": 1410},
        "max_threads_per_processor": 2048,
        "hourly_rate": 1.2,
        "graval": {
            "iterations": 2,
            "estimate": 58,
        },
    },
    "a100_sxm": {
        "model_name_check": "A100.?SXM.?.?80GB",
        "memory": 80,
        "major": 8,
        "minor": 0,
        "tensor_cores": 432,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": True,
        "processors": 108,
        "clock_rate": {"base": 1275, "boost": 1410},
        "max_threads_per_processor": 2048,
        "hourly_rate": 1.25,
        "graval": {
            "iterations": 3,
            "estimate": 70,
        },
    },
    "h100": {
        "model_name_check": "H100.*PCIe",
        "memory": 80,
        "major": 9,
        "minor": 0,
        "tensor_cores": 456,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 114,
        "clock_rate": {"base": 1095, "boost": 1755},
        "max_threads_per_processor": 2048,
        "hourly_rate": 1.79,
        "graval": {
            "iterations": 2,
            "estimate": 62,
        },
    },
    "h100_nvl": {
        "model_name_check": "H100.*NVL",
        "memory": 96,
        "major": 9,
        "minor": 0,
        "tensor_cores": 456,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": True,
        "processors": 132,
        "clock_rate": {"base": 1590, "boost": 1980},
        "max_threads_per_processor": 2048,
        "hourly_rate": 2.25,
        "graval": {
            "iterations": 3,
            "estimate": 75,
        },
    },
    "h100_sxm": {
        "model_name_check": "H100.*HBM3",
        "memory": 80,
        "major": 9,
        "minor": 0,
        "tensor_cores": 528,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": True,
        "processors": 132,
        "clock_rate": {"base": 1590, "boost": 1980},
        "max_threads_per_processor": 2048,
        "hourly_rate": 2.35,
        "graval": {
            "iterations": 5,
            "estimate": 70,
        },
    },
    "h800": {
        "model_name_check": "H800.*PCIe",
        "memory": 80,
        "major": 9,
        "minor": 0,
        "tensor_cores": 456,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": False,
        "processors": 114,
        "clock_rate": {"base": 1095, "boost": 1755},
        "max_threads_per_processor": 2048,
        "hourly_rate": 1.5,
        "graval": {
            "iterations": 3,
            "estimate": 75,
        },
    },
    "h20": {
        "model_name_check": " H20$",
        "memory": 96,
        "processors": 78,
        "clock_rate": {"base": 1590, "boost": 1980},
        "max_threads_per_processor": 1024,
        "hourly_rate": 0.6,
        "graval": {
            "iterations": 1,
            "estimate": 300,
        },
    },
    "h200": {
        "model_name_check": " H200",
        "memory": 140,
        "major": 9,
        "minor": 0,
        "tensor_cores": 528,
        "concurrent_kernels": True,
        "ecc": True,
        "sxm": True,
        "processors": 132,
        "clock_rate": {"base": 1590, "boost": 1980},
        "max_threads_per_processor": 2048,
        "hourly_rate": 2.75,
        "graval": {
            "iterations": 3,
            "estimate": 70,
        },
    },
    # XXX Not enabled, supported by new graval but otherwise disabled.
    "mi300x": {
        "model_name_check": "gfx942:sramecc",
        "memory": 192,
        "processors": 304,
        "clock_rate": {"base": 1600, "boost": 2100},
        "max_threads_per_processor": 256,
        "hourly_rate": 3.0,
        "graval": {
            "iterations": 2,
            "estimate": 75,
        },
    },
    "b200": {
        "model_name_check": " B200",
        "memory": 192,
        "processors": 148,
        "clock_rate": {"base": 1590, "boost": 1965},
        "max_threads_per_processor": 1024,
        "hourly_rate": 4.5,
        "graval": {
            "iterations": 2,
            "estimate": 75,
        },
    },
}


def normalize_scores(gpu_dict):
    """
    Calculate score for each supported GPU and provide a normalized range (based on price).
    """
    scores = {}
    for model, info in gpu_dict.items():
        score = info["hourly_rate"]
        scores[model] = score
    sorted_scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))
    max_score = max(scores.values())
    normalized_scores = {}
    for model, score in sorted_scores.items():
        normalized_scores[model] = score / max_score
    return normalized_scores


COMPUTE_MULTIPLIER = normalize_scores(SUPPORTED_GPUS)
COMPUTE_MIN = min([score for score in COMPUTE_MULTIPLIER.values()])
COMPUTE_UNIT_PRICE_BASIS = max([info["hourly_rate"] for info in SUPPORTED_GPUS.values()])
