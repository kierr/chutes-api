import gc
import os
import uuid
import orjson as json
import asyncio
import aiohttp
import random
import traceback
import ctypes
from typing import Any, Dict, List, Tuple
from loguru import logger
from sqlalchemy import select, text, exists
import api.database.orms  # noqa
import api.miner_client as miner_client
from api.config import settings
from api.chute.schemas import RollingUpdate, Chute
from api.database import get_session
from api.instance.schemas import Instance
from api.instance.util import invalidate_instance_cache, cleanup_instance_conn_tracking
from api.util import encrypt_instance_request, notify_deleted, semcomp
from api.chute.util import get_one
from watchtower import check_runint

ENETUNREACH_TOKEN = "ENETUNREACH"
REDIS_PREFIX = "conntestfail:"
PROXY_URL = "https://proxy.chutes.ai/misc/proxy?url=ping"
LBPING_URL = "https://api.chutes.ai/_lbping"

NETNANNY = ctypes.CDLL("/usr/local/lib/chutes-nnverify.so")
NETNANNY.verify.argtypes = [ctypes.c_char_p, ctypes.c_char_p, ctypes.c_uint8]
NETNANNY.verify.restype = ctypes.c_int

import chutes as _chutes_pkg  # noqa: E402

_aegis_verify_path = os.path.join(os.path.dirname(_chutes_pkg.__file__), "chutes-aegis-verify.so")
AEGIS_VERIFY = ctypes.CDLL(_aegis_verify_path)
AEGIS_VERIFY.verify.argtypes = [ctypes.c_char_p, ctypes.c_char_p, ctypes.c_uint8]
AEGIS_VERIFY.verify.restype = ctypes.c_int


async def _post_connectivity(instance: Instance, endpoint: str) -> Dict[str, Any]:
    enc_path, _ = encrypt_instance_request("/_connectivity", instance, hex_encode=True)
    payload, _ = encrypt_instance_request(json.dumps({"endpoint": endpoint}), instance)
    async with miner_client.post(
        instance.miner_hotkey,
        f"/{enc_path}",
        payload,
        instance=instance,
        timeout=30.0,
    ) as resp:
        resp.raise_for_status()
        return await resp.json()


async def _post_netnanny_challenge(instance: Instance, challenge: str) -> Dict[str, Any]:
    enc_path, _ = encrypt_instance_request("/_netnanny_challenge", instance, hex_encode=True)
    payload, _ = encrypt_instance_request(json.dumps({"challenge": challenge}), instance)
    async with miner_client.post(
        instance.miner_hotkey,
        f"/{enc_path}",
        payload,
        instance=instance,
        timeout=15.0,
    ) as resp:
        resp.raise_for_status()
        return await resp.json()


def _pick_random_connect_test() -> str:
    candidates = list(getattr(settings, "conntest_urls", []) or [])
    if not candidates:
        candidates = ["https://icanhazip.com", "https://www.google.com/"]
    return random.choice(candidates)


async def _hard_delete_instance(session, instance: Instance, reason: str) -> None:
    chute = (
        (await session.execute(select(Chute).where(Chute.chute_id == instance.chute_id)))
        .unique()
        .scalar_one_or_none()
    )
    if not chute:
        return
    if "too many requests" in reason.lower():
        if semcomp(instance.chutes_version or "0.0.0", "0.3.58") < 0:
            logger.warning("Ignoring 429 from older chutes version...")
        else:
            logger.error(
                f"Hmmm, why 429?: {instance.instance_id=} {instance.miner_hotkey=} {instance.chute_id=} {chute.name=} {chute.chute_id=}"
            )
        return
    if chute.public or "affine" in chute.name.lower():
        return

    logger.error(
        f"ðŸ›‘ HARD FAIL (egress policy violation): deleting {instance.instance_id=} "
        f"{instance.miner_hotkey=} {instance.chute_id=} {chute.name=} {chute.chute_id=}. Reason: {reason}"
    )
    await session.delete(instance)
    await session.execute(
        text(
            "UPDATE instance_audit SET deletion_reason = :reason WHERE instance_id = :instance_id"
        ),
        {"instance_id": instance.instance_id, "reason": f"CONNPROBE: {reason}"},
    )
    await notify_deleted(instance, message=reason)
    await invalidate_instance_cache(instance.chute_id, instance_id=instance.instance_id)
    await session.commit()
    await cleanup_instance_conn_tracking(instance.chute_id, instance.instance_id)


async def _record_failure_or_delete(session, instance: Instance, hard_reason: str | None) -> None:
    if hard_reason:
        await _hard_delete_instance(session, instance, hard_reason)
        return
    rkey = f"{REDIS_PREFIX}{instance.instance_id}"
    try:
        failure_count = await settings.redis_client.incr(rkey)
        await settings.redis_client.expire(rkey, 900)
    except Exception as redis_exc:
        logger.warning(f"Redis error tracking failures for {instance.instance_id}: {redis_exc}")
        failure_count = 1
    if failure_count >= 5:
        await _hard_delete_instance(
            session,
            instance,
            "Failed 5 or more consecutive connectivity probes.",
        )


async def _verify_netnanny(instance: Instance, allow_external_egress: bool) -> None:
    """
    Raises RuntimeError with a descriptive reason if verification fails.
    """
    challenge = str(uuid.uuid4())
    res = await _post_netnanny_challenge(instance, challenge)
    miner_hash = res.get("hash")
    miner_egress = res.get("allow_external_egress")
    if miner_hash is None or miner_egress is None:
        raise RuntimeError(
            "Netnanny challenge missing required fields (hash/allow_external_egress)."
        )
    if bool(miner_egress) != bool(allow_external_egress):
        raise RuntimeError(
            f"Netnanny reported allow_external_egress={miner_egress} "
            f"but chute requires {allow_external_egress}."
        )
    # Use aegis-verify for >= 0.5.5, netnanny for older instances.
    if semcomp(instance.chutes_version or "0.0.0", "0.5.5") >= 0:
        if not AEGIS_VERIFY.verify(
            challenge.encode(), miner_hash.encode(), ctypes.c_uint8(allow_external_egress)
        ):
            raise RuntimeError("Aegis verify() returned failure.")
    else:
        if not NETNANNY.verify(
            challenge.encode(), miner_hash.encode(), ctypes.c_uint8(allow_external_egress)
        ):
            raise RuntimeError("Netnanny verify() returned failure.")


async def check_instance_connectivity(
    instance: Instance, delete_on_failure: bool = True
) -> Tuple[str, bool]:
    logger.info(
        f"Connectivity check: {instance.instance_id=} {instance.miner_hotkey=} {instance.chute_id=}"
    )
    chute = await get_one(instance.chute_id)
    if not chute or semcomp(chute.chutes_version or "0.0.0", "0.3.50") < 0:
        logger.warning(f"Unable to perform connectivity tests for {instance.chute_id=}")
        return instance.instance_id, True

    allow_egress = chute.allow_external_egress
    # Runtime integrity check.
    try:
        if not await check_runint(instance):
            if delete_on_failure:
                async with get_session() as session:
                    await _record_failure_or_delete(session, instance, hard_reason=None)
            return instance.instance_id, False
    except Exception as exc:
        logger.warning(f"RUNINT: timeout/error checking {instance.instance_id=}: {exc}")
        if delete_on_failure:
            async with get_session() as session:
                await _record_failure_or_delete(session, instance, hard_reason=None)
        return instance.instance_id, False

    try:
        await _verify_netnanny(instance, allow_egress)
        logger.success(f"ðŸ”’ netnanny challenge verified for {instance.instance_id=}")
    except RuntimeError as exc:
        # RuntimeError means actual verification failure (hash mismatch, wrong egress setting, etc.)
        # This is a hard fail - the miner is misreporting or tampering
        logger.error(
            f"âŒ netnanny verification FAILED for {instance.instance_id=}: {str(exc)}\n{traceback.format_exc()}"
        )
        if delete_on_failure:
            async with get_session() as session:
                await _hard_delete_instance(
                    session,
                    instance,
                    f"Netnanny verification failed: {exc}",
                )
        return instance.instance_id, False
    except Exception as exc:
        # Other exceptions (timeouts, connection errors, etc.) are soft failures
        logger.error(
            f"âŒ netnanny probe failed (connection/timeout) for {instance.instance_id=}: {str(exc)}\n{traceback.format_exc()}"
        )
        if delete_on_failure:
            async with get_session() as session:
                await _record_failure_or_delete(session, instance, hard_reason=None)
        return instance.instance_id, False

    random_test = _pick_random_connect_test()
    if allow_egress:
        required_successes = [LBPING_URL, random_test]
        try:
            for target in required_successes:
                result = await _post_connectivity(instance, target)
                if not result.get("connection_established"):
                    raise RuntimeError(
                        f"Egress allowed, but connection_established is False for {target}; "
                        f"error={result.get('error')}"
                    )
            logger.success(
                f"âœ… egress allowed & verified for {instance.instance_id=} (lbping + random ok)"
            )
            try:
                await settings.redis_client.delete(f"{REDIS_PREFIX}{instance.instance_id}")
            except Exception:
                pass
            return instance.instance_id, True
        except Exception as exc:
            logger.error(
                f"âŒ egress-allowed probe failed for {instance.instance_id=}: {exc}\n"
                f"{traceback.format_exc()}"
            )
            if delete_on_failure:
                async with get_session() as session:
                    await _record_failure_or_delete(session, instance, hard_reason=None)
            return instance.instance_id, False
    else:
        # Egress is supposed to be BLOCKED
        try:
            # First verify proxy works (required connectivity)
            proxy_res = await _post_connectivity(instance, PROXY_URL)
            if not proxy_res.get("connection_established") or proxy_res.get("status_code") != 200:
                raise RuntimeError(
                    f"Proxy must succeed but got connection_established="
                    f"{proxy_res.get('connection_established')} status_code={proxy_res.get('status_code')} "
                    f"error={proxy_res.get('error')}"
                )

            # Now check that direct egress is properly blocked
            # This is the ONLY case that should be a hard fail - if egress works when it shouldn't
            disallowed = [LBPING_URL, random_test]
            for target in disallowed:
                res = await _post_connectivity(instance, target)
                conn = bool(res.get("connection_established"))
                if conn:
                    # THIS is an actual egress policy violation - hard fail immediately
                    bad_violation_reason = (
                        f"Egress disabled but connection_established is True for {target}"
                    )
                    logger.error(
                        f"ðŸš¨ EGRESS POLICY VIOLATION: {instance.instance_id=} connected to {target} "
                        f"when egress should be blocked"
                    )
                    if delete_on_failure:
                        async with get_session() as session:
                            await _hard_delete_instance(session, instance, bad_violation_reason)
                    return instance.instance_id, False

            logger.success(
                f"âœ… egress blocked & verified for {instance.instance_id=} "
                f"(proxy ok, direct outbound blocked with ENETUNREACH)"
            )
            try:
                await settings.redis_client.delete(f"{REDIS_PREFIX}{instance.instance_id}")
            except Exception:
                pass
            return instance.instance_id, True

        except Exception as exc:
            # Connection failures, timeouts, etc. are SOFT failures - not policy violations
            # The instance might just be having network issues
            logger.error(
                f"âŒ egress-blocked probe failed for {instance.instance_id=}: {exc}\n"
                f"{traceback.format_exc()}"
            )
            if delete_on_failure:
                async with get_session() as session:
                    # Use soft failure with retry limit, NOT hard delete
                    await _record_failure_or_delete(session, instance, hard_reason=None)
            return instance.instance_id, False


async def check_connectivity_all(max_concurrent: int = 32) -> None:
    # Make sure we can do the tests...
    smoke_tests = [
        PROXY_URL,
        LBPING_URL,
        "https://icanhazip.com",
        "https://www.google.com",
    ]
    for url in smoke_tests:
        async with aiohttp.ClientSession(raise_for_status=True) as session:
            async with session.get(url) as resp:
                assert resp.ok
                logger.success(f"Successfully pinged {url=} in smoke test.")

    semaphore = asyncio.Semaphore(max_concurrent)

    async def guarded(instance: Instance):
        async with semaphore:
            return await check_instance_connectivity(instance)

    async with get_session() as session:
        q = select(Instance).where(
            Instance.active.is_(True),
            ~exists(
                select(1)
                .select_from(RollingUpdate)
                .where(RollingUpdate.chute_id == Instance.chute_id)
            ),
        )
        stream = await session.stream(q)
        instances: List[Instance] = []
        async for row in stream.unique():
            instances.append(row[0])

    logger.info(f"Connectivity: checking {len(instances)} active instances")
    results = await asyncio.gather(*(guarded(i) for i in instances))
    ok = sum(1 for _, passed in results if passed)
    bad = len(results) - ok
    logger.success("=" * 80)
    logger.success(f"Connectivity check complete: {ok} passed, {bad} failed")
    if bad:
        failed_ids = [iid for iid, passed in results if not passed]
        logger.warning(f"Failed instances: {failed_ids}")


if __name__ == "__main__":
    gc.set_threshold(5000, 50, 50)
    asyncio.run(check_connectivity_all())
